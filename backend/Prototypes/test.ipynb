{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4278b4b392c54933a06c6269b5d29e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2009FallHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5914e1955f334e03b49a088878a48991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2009SpringHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5abc67909a3421397b281d59bc62cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2010FallHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4af8e14de6438587cb595c25c3f9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2010SpringHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cae761652f4c33b250228332072f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2010WinterHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9a32b2f82041f5a9ac64e3505c521a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2011FallHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae54267489c489f82f34f13e9b4b274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2011SpSumHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d16cce95b64495b2ff0acb632de892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2011WinterHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7410ba3d47f544d3a764afff8b7b2a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2012FallHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8077d344f54e3ba15c07c3079e0914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2012SummerHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5471705b7cb9407492fb3cc7e4453a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2013FallHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f4e0208a594eabb4af3b369bdec473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2013SummerHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d14cfa82e34a7ba8645a9b1a9a5036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2014FallHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b31366a4544cb89cfa13d4d1ebfc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2014SummerHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f17100934b54dcfb8f153a994bf52fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2015FallHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de9a33703cd4a599f173af065b56f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2015SpringHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f1e1b697e14a4bbe600a7a6e9005d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2015WinterHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ddb426149b4dbd961c0e7737570626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2016FallHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4daafd7b8204d6998bdf06bf2305f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2016SummerHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b2b7f40537480fb8a44393823ff40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2016WinterHorizons-1.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953d1ce050c94ccca70ba9c8d9fa1a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2017FallHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dfd9cf43bc4f92a7315404a832e377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2017SummerHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e49f7aac82041f6a9c9f33d7495f5fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2018MBBChampsHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3827ed22e26472a83f018891e17debb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2018WinterHorizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec14bc2a78547598b40fc62afcbee7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GracelandU-Horizons_FA23-WEB-NEW.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b61faed05cf4acca040a412423e59e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing GracelandU-Horizons_SP23_WEB.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f2277ec050411c83824c0fd888a6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Horizons-Winter2017v2.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16460f1bf55349ab9f6b4370caadc0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing HorizonsFA18_FINAL.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008a235a4b264adca905e29214c8123a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing HorizonsSU18_FINAL.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22da08f8cd60455ca13583072c4e8181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing HorizonsSU19Issue.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d9435a05684358a37a548f31e0019e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing HorizonsWinter2009.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f429e6a60fc4ca3bb5f71c3e41e4522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Horizons_FA19.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9653161e42940eca253aa896981ac77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Horizons_FA20-FINAL-WEB.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8f23a8ca5b4b329a90fd2a13318bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Horizons_FA22-FINAL-WEB.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7c7f2024cf4ab0a3f6831996336941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Horizons_SP19_WEB.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824e1306a5cc4613b75ae36c3a45c92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Horizons_SP22_WEB_Spread-NEW.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19daefd085094b2d87e4bac8f5f94ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Winter2013Horizons.pdf: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'document_name': '2009FallHorizons.pdf',\n",
       "  'page_number': 0,\n",
       "  'page_char_count': 128,\n",
       "  'page_word_count': 20,\n",
       "  'page_sentence_count_raw': 3,\n",
       "  'page_token_count': 32.0,\n",
       "  'text': 'Fall 2009 Vol. 25, No. 2 Alumni and Friends Magazine  Sherri Kirkpatrick’s HealthEd Connect Serves the World’s Neediest Children'},\n",
       " {'document_name': '2009FallHorizons.pdf',\n",
       "  'page_number': 1,\n",
       "  'page_char_count': 2418,\n",
       "  'page_word_count': 434,\n",
       "  'page_sentence_count_raw': 21,\n",
       "  'page_token_count': 604.5,\n",
       "  'text': 'I  am dressed for SPEC in this impromptu photo with  Sherri and Jac Kirkpatrick. They joined 1,200 high  school students and volunteers in late July for the an- nual Community of Christ SPECTACULAR event on our  Lamoni campus. See the photos on pages 8-11 of this issue  of Horizons for glimpses of the energy and excitement that  prevail during this wonderful weeklong camp. It was my pleasure to meet with Sherri and Jac as they  inaugurate their new HealthEd Connect project that will  bring village health care and community-based orphan  programs to Sub-Sahara Africa, and help provide for  the significant number of children in those countries  who have AIDS. Sherri is truly the Albert Schweitzer of  Graceland. She has traveled the world bringing health- care education and hope to those most in need. Her work  with the Graceland-affiliated International Health Center  for the last 20 years has been nothing short of miraculous.  She has taken students from Graceland’s School of Nurs- ing to the far reaches of our planet in the name of higher  education and humanitarian service. Jac has spent those same years as a CofC Apostle to  Africa, India and other third-world nations. He helped  develop and launch the church’s WorldService Corps. He  understands how to function in these far-and-away places  in ways that would baffle the rest of us. I can’t imagine a  couple more empowered to drive forward the noble goals  of HealthEd Connect. They complement each other with  well-honed organizational skills and a unique cultural  understanding of the third world. Their backgrounds are  a perfect fit for the work ahead.  Sherri and I have known each other all our lives. We  grew up in the same area and attended the same CofC  congregation in Independence, MO. It is humbling to me to  see Sherri and Jac opening their hearts and rolling up their  sleeves to help some of the neediest children in the world.  I am proud that Graceland has been involved with the  International Health Center over the years and that we will  continue to play a supportive role with HealthEd Connect  and Sherri’s life-long commitment to these children. Please read Sherri’s heartwarming journal from the re- cent trip she and Jac took to Sub-Sahara Africa to launch  HealthEd Connect. Her words and Jac’s insightful images  appear on pages 2-6 of this issue of Horizons. John Sellars Graceland President from the President'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz  # pymupdf\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    \"\"\"Performs minor formatting on text.\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "    return cleaned_text\n",
    "\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Opens a PDF file, reads its text content page by page, and collects statistics.\n",
    "\n",
    "    Parameters:\n",
    "        pdf_path (str): The file path to the PDF document to be opened and read.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dictionaries containing extracted data for each page.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    document_name = os.path.basename(pdf_path)  # Extract document name\n",
    "    pages_and_texts = []\n",
    "    \n",
    "    for page_number, page in tqdm(enumerate(doc), desc=f\"Processing {document_name}\"):\n",
    "        text = page.get_text()\n",
    "        text = text_formatter(text)\n",
    "        pages_and_texts.append({\n",
    "            \"document_name\": document_name,\n",
    "            \"page_number\": page_number,  # Adjust page numbers\n",
    "            \"page_char_count\": len(text),\n",
    "            \"page_word_count\": len(text.split(\" \")),\n",
    "            \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "            \"page_token_count\": len(text) / 4,\n",
    "            \"text\": text\n",
    "        })\n",
    "    \n",
    "    return pages_and_texts\n",
    "\n",
    "# Directory containing PDFs\n",
    "directory_path = r\"C:\\Users\\IT Lab VR\\Desktop\\LamoniAI\\GracelandPDFs\\Horizons\"\n",
    "pages_and_text = []\n",
    "\n",
    "# Process all PDFs in the Horizons directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        pages_and_text.extend(open_and_read_pdf(file_path))\n",
    "\n",
    "# Preview first two entries\n",
    "pages_and_text[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1006.00\n",
       "mean      884.22\n",
       "std       551.64\n",
       "min         0.00\n",
       "25%       537.56\n",
       "50%       869.00\n",
       "75%      1134.25\n",
       "max      3441.25\n",
       "Name: page_token_count, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_text)\n",
    "df.head()\n",
    "df.page_token_count.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x1c0458afe50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using spacy because it's more robust then just splitting sentences from \". \" and also the news paper scan didn't pick up the period\n",
    "from spacy.lang.en import English \n",
    "nlp = English()\n",
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d45f4a9383a450a97ede035319b402a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_text):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "\n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_name': '2009FallHorizons.pdf',\n",
       " 'page_number': 0,\n",
       " 'page_char_count': 128,\n",
       " 'page_word_count': 20,\n",
       " 'page_sentence_count_raw': 3,\n",
       " 'page_token_count': 32.0,\n",
       " 'text': 'Fall 2009 Vol. 25, No. 2 Alumni and Friends Magazine  Sherri Kirkpatrick’s HealthEd Connect Serves the World’s Neediest Children',\n",
       " 'sentences': ['Fall 2009 Vol.',\n",
       "  '25, No.',\n",
       "  '2 Alumni and Friends Magazine  Sherri Kirkpatrick’s HealthEd Connect Serves the World’s Neediest Children'],\n",
       " 'page_sentence_count_spacy': 3}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1006.00</td>\n",
       "      <td>1006.00</td>\n",
       "      <td>1006.00</td>\n",
       "      <td>1006.00</td>\n",
       "      <td>1006.00</td>\n",
       "      <td>1006.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.03</td>\n",
       "      <td>3536.86</td>\n",
       "      <td>665.27</td>\n",
       "      <td>34.19</td>\n",
       "      <td>884.22</td>\n",
       "      <td>26.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.90</td>\n",
       "      <td>2206.57</td>\n",
       "      <td>474.01</td>\n",
       "      <td>63.06</td>\n",
       "      <td>551.64</td>\n",
       "      <td>38.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.00</td>\n",
       "      <td>2150.25</td>\n",
       "      <td>387.00</td>\n",
       "      <td>15.25</td>\n",
       "      <td>537.56</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.00</td>\n",
       "      <td>3476.00</td>\n",
       "      <td>624.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>869.00</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.00</td>\n",
       "      <td>4537.00</td>\n",
       "      <td>830.75</td>\n",
       "      <td>37.00</td>\n",
       "      <td>1134.25</td>\n",
       "      <td>34.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>47.00</td>\n",
       "      <td>13765.00</td>\n",
       "      <td>5797.00</td>\n",
       "      <td>850.00</td>\n",
       "      <td>3441.25</td>\n",
       "      <td>541.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1006.00          1006.00          1006.00                  1006.00   \n",
       "mean         15.03          3536.86           665.27                    34.19   \n",
       "std          10.90          2206.57           474.01                    63.06   \n",
       "min           0.00             0.00             1.00                     1.00   \n",
       "25%           6.00          2150.25           387.00                    15.25   \n",
       "50%          13.00          3476.00           624.00                    26.00   \n",
       "75%          21.00          4537.00           830.75                    37.00   \n",
       "max          47.00         13765.00          5797.00                   850.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  \n",
       "count           1006.00                    1006.00  \n",
       "mean             884.22                      26.22  \n",
       "std              551.64                      38.61  \n",
       "min                0.00                       0.00  \n",
       "25%              537.56                       8.00  \n",
       "50%              869.00                      22.00  \n",
       "75%             1134.25                      34.00  \n",
       "max             3441.25                     541.00  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spacy split a more than just on \". \"\n",
    "df = pd.DataFrame(pages_and_text)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chunk size\n",
    "num_sentence_chunk_size = 10\n",
    "\n",
    "def split_list(input_list: list, slice_size: int=num_sentence_chunk_size) -> list[list[str]]:\n",
    "    return [input_list[i:i+slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "test_list = list(range(25))\n",
    "split_list(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be6abad4f2648c4886daddd5c3d9ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split sentences in chunks\n",
    "for item in tqdm(pages_and_text):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                        slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a0c949fa1349999abc4312f33a558b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3127"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting each chunk into its own item\n",
    "import re\n",
    "\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_text):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"document_name\"] = item[\"document_name\"]\n",
    "        \n",
    "\n",
    "        #join the lists of paragraphs \n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \",\" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])',r'. \\1', joined_sentence_chunk)\n",
    "        joined_sentence_chunk = re.sub(r'\\?([A-Z])',r'. \\1', joined_sentence_chunk)\n",
    "        joined_sentence_chunk = re.sub(r'\\!([A-Z])',r'. \\1', joined_sentence_chunk)\n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4\n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'document_name': 'Horizons_FA19.pdf',\n",
       "  'sentence_chunk': 'ANNUAL REPORT 2019 HORIZONS  | 27 “I believe we are navigating the journey between the continuity of our values and mission with an everchanging and ever more complex world.” O\\u200a ver and over, we hear that higher education is changing, and it is — rapidly. The days when a student applied to one or two schools, attended one of them on campus for four years and graduated with a bachelor’s degree are disappearing rapidly. Students now compare financial aid packages from multiple schools before choosing based on cost, degree programs are earned online, and the public is even growing skeptical about the essential value of higher education. To survive, universities must prove that what they offer is worth the investment and better than the competition. Those that do not, disappear. For Graceland, however, the challenge is not just delivering well- designed courses. Of course, we need to do that, but we must also be true to our core identity: a genuine community of integrity and authenticity that focuses on developing citizens empowered to make a better, more sustainable world community. While that goal remains constant, the way to achieve that in 2020 cannot just be what worked in the past. The times in which we live are changing so quickly; our approach to education must evolve to keep Graceland strong for now and into the future.',\n",
       "  'chunk_char_count': 1346,\n",
       "  'chunk_word_count': 227,\n",
       "  'chunk_token_count': 336.5}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(pages_and_chunks, k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_name': '2009FallHorizons.pdf',\n",
       " 'sentence_chunk': 'I am dressed for SPEC in this impromptu photo with Sherri and Jac Kirkpatrick. They joined 1,200 high school students and volunteers in late July for the an- nual Community of Christ SPECTACULAR event on our Lamoni campus. See the photos on pages 8-11 of this issue of Horizons for glimpses of the energy and excitement that prevail during this wonderful weeklong camp. It was my pleasure to meet with Sherri and Jac as they inaugurate their new HealthEd Connect project that will bring village health care and community-based orphan programs to Sub-Sahara Africa, and help provide for the significant number of children in those countries who have AIDS. Sherri is truly the Albert Schweitzer of Graceland. She has traveled the world bringing health- care education and hope to those most in need. Her work with the Graceland-affiliated International Health Center for the last 20 years has been nothing short of miraculous. She has taken students from Graceland’s School of Nurs- ing to the far reaches of our planet in the name of higher education and humanitarian service. Jac has spent those same years as a CofC Apostle to Africa, India and other third-world nations. He helped develop and launch the church’s WorldService Corps.',\n",
       " 'chunk_char_count': 1234,\n",
       " 'chunk_word_count': 204,\n",
       " 'chunk_token_count': 308.5,\n",
       " 'score': nan}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get chunks with under 120 tokens of length. These chunks probaly don't have a lot of usefull info and are most likely headings\n",
    "df = pd.DataFrame(pages_and_chunks)\n",
    "min_token_length = 120\n",
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
    "pages_and_chunks_over_min_token_len[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note for future research best embedding models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
    "                                      device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ecc6acc4234bf48daf17e839a1da21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Running on slow bum CPU\n",
    "# CPU no batching takes 9.12 mins\n",
    "# for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "#     item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Embedding model using GPU\n",
    "\n",
    "# embedding_model.to(\"cuda\")\n",
    "\n",
    "# for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "#     item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 22s\n",
      "Wall time: 10.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01565549,  0.05134168,  0.00469097, ...,  0.01968559,\n",
       "         0.04327909,  0.00772345],\n",
       "       [-0.00152143,  0.09567615,  0.00168284, ...,  0.02596665,\n",
       "         0.01168879,  0.02988   ],\n",
       "       [ 0.07282847,  0.04050159, -0.01421707, ..., -0.05362667,\n",
       "         0.00808336, -0.01800963],\n",
       "       ...,\n",
       "       [ 0.00455149,  0.10821065,  0.01038493, ..., -0.0101995 ,\n",
       "        -0.02181573,  0.00449938],\n",
       "       [ 0.01957653,  0.06110422, -0.00176075, ..., -0.00284812,\n",
       "         0.04169122, -0.02332427],\n",
       "       [ 0.03256436,  0.10554793, -0.04640035, ...,  0.01929192,\n",
       "         0.05620907,  0.01205661]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# running with CPU chunking\n",
    "# CPU with batching takes 7.16 mins\n",
    "text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks_over_min_token_len]\n",
    "\n",
    "text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
    " batch_size=16, convert_to_tensors=True)\n",
    "\n",
    "text_chunk_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save embeddings\n",
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>score</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009FallHorizons.pdf</td>\n",
       "      <td>I am dressed for SPEC in this impromptu photo ...</td>\n",
       "      <td>1234</td>\n",
       "      <td>204</td>\n",
       "      <td>308.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ 1.56554971e-02  5.13416603e-02  4.69097216e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009FallHorizons.pdf</td>\n",
       "      <td>He understands how to function in these far-an...</td>\n",
       "      <td>1095</td>\n",
       "      <td>187</td>\n",
       "      <td>273.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-1.52143801e-03  9.56762135e-02  1.68284110e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009FallHorizons.pdf</td>\n",
       "      <td>Administration John Sellars, Ph. D. \\t Preside...</td>\n",
       "      <td>3075</td>\n",
       "      <td>520</td>\n",
       "      <td>768.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ 7.28284568e-02  4.05015796e-02 -1.42170694e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009FallHorizons.pdf</td>\n",
       "      <td>She and her husband Jac Kirkpatrick are now la...</td>\n",
       "      <td>1182</td>\n",
       "      <td>204</td>\n",
       "      <td>295.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ 4.19127801e-03  6.59697279e-02 -4.01556864e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009FallHorizons.pdf</td>\n",
       "      <td>HealthEd Connect Expands Sherri’s Lifelong Pas...</td>\n",
       "      <td>1219</td>\n",
       "      <td>192</td>\n",
       "      <td>304.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ 1.52009120e-02  9.64530185e-02 -1.43753057e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          document_name                                     sentence_chunk  \\\n",
       "0  2009FallHorizons.pdf  I am dressed for SPEC in this impromptu photo ...   \n",
       "1  2009FallHorizons.pdf  He understands how to function in these far-an...   \n",
       "2  2009FallHorizons.pdf  Administration John Sellars, Ph. D. \\t Preside...   \n",
       "3  2009FallHorizons.pdf  She and her husband Jac Kirkpatrick are now la...   \n",
       "4  2009FallHorizons.pdf  HealthEd Connect Expands Sherri’s Lifelong Pas...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count score  \\\n",
       "0              1234               204             308.50   NaN   \n",
       "1              1095               187             273.75   NaN   \n",
       "2              3075               520             768.75   NaN   \n",
       "3              1182               204             295.50   NaN   \n",
       "4              1219               192             304.75   NaN   \n",
       "\n",
       "                                           embedding  \n",
       "0  [ 1.56554971e-02  5.13416603e-02  4.69097216e-...  \n",
       "1  [-1.52143801e-03  9.56762135e-02  1.68284110e-...  \n",
       "2  [ 7.28284568e-02  4.05015796e-02 -1.42170694e-...  \n",
       "3  [ 4.19127801e-03  6.59697279e-02 -4.01556864e-...  \n",
       "4  [ 1.52009120e-02  9.64530185e-02 -1.43753057e-...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embeddings_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "\n",
    "text_chunks_and_embeddings_df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2469, 768])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# convert embeddins colum back to np.array from csv\n",
    "# text_chunks_and_embeddings_df_load = pd.read_csv(\"text_chunk_embeddings_df.csv\")\n",
    "# text_chunks_and_embeddings_df[\"embedding\"] = text_chunks_and_embeddings_df_load[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\")))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "embeddings = text_chunks_and_embeddings_df[\"embedding\"].tolist()\n",
    "embeddings = torch.tensor(np.stack(text_chunks_and_embeddings_df[\"embedding\"].tolist(), axis=0), dtype=torch.float32).to(device)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Graceland\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "from sentence_transformers import util, SentenceTransformer\n",
    "from time import perf_counter as timer\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
    "                                      device=device)\n",
    "\n",
    "query = \"Graceland\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "#Note: embed query with the same model you embedded your passage with.\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to get scores on 2469 embeddings: 0.00035 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.5841, 0.5794, 0.5716, 0.5634, 0.5628], device='cuda:0'),\n",
       "indices=tensor([2399,  188, 1899,  796,  175], device='cuda:0'))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
    "end_timer = timer()\n",
    "\n",
    "print(f\"Time taken to get scores on {(len(embeddings))} embeddings: {end_timer-start_time:.5f} seconds.\")\n",
    "\n",
    "# Get top 5 results of query search\n",
    "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
    "top_results_dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_name': '2009FallHorizons.pdf',\n",
       " 'sentence_chunk': 'I am dressed for SPEC in this impromptu photo with Sherri and Jac Kirkpatrick. They joined 1,200 high school students and volunteers in late July for the an- nual Community of Christ SPECTACULAR event on our Lamoni campus. See the photos on pages 8-11 of this issue of Horizons for glimpses of the energy and excitement that prevail during this wonderful weeklong camp. It was my pleasure to meet with Sherri and Jac as they inaugurate their new HealthEd Connect project that will bring village health care and community-based orphan programs to Sub-Sahara Africa, and help provide for the significant number of children in those countries who have AIDS. Sherri is truly the Albert Schweitzer of Graceland. She has traveled the world bringing health- care education and hope to those most in need. Her work with the Graceland-affiliated International Health Center for the last 20 years has been nothing short of miraculous. She has taken students from Graceland’s School of Nurs- ing to the far reaches of our planet in the name of higher education and humanitarian service. Jac has spent those same years as a CofC Apostle to Africa, India and other third-world nations. He helped develop and launch the church’s WorldService Corps.',\n",
       " 'chunk_char_count': 1234,\n",
       " 'chunk_word_count': 204,\n",
       " 'chunk_token_count': 308.5}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not great results\n",
    "pages_and_chunks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For vector search read up on Faiss, nearest neighbour search\n",
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Alumna Chris Helene Bridge\n",
      "\n",
      "Results:\n",
      "Score: 0.5127\n",
      "Page number: 2012FallHorizons.pdf\n",
      "Text:\n",
      "Graceland is now a 1st-tier school in the arts. Students from around the world\n",
      "will follow their hearts and dreams to Graceland just for the chance to work and\n",
      "learn in this magnificent facility. In the short-term, I have some very exciting\n",
      "travel plans coming up this fall to meet with donors concerning athletics, the\n",
      "sciences, the arts, music, agriculture, and more. In the long-term, I feel an\n",
      "excitement for Grace- land’s future that seems to grow as each day passes. I\n",
      "thank you for making this excitement possible. Sincerely, John Sellars, Ph. D.\n",
      "President Annual Report G r a c e l a n d U n i v e r s i t y 2 0 12\n",
      "\n",
      "\n",
      "Score: 0.4947\n",
      "Page number: 2013FallHorizons.pdf\n",
      "Text:\n",
      "Fall 2013 Horizons  | 5 Powell House Created Tom Powell ’73 joined the Graceland\n",
      "faculty in 1980 and then served as VP of Student Life from 1984 until January\n",
      "2010. Graceland honors Tom’s legacy by naming a new mens’ house, Powell House.\n",
      "The Powell House symbol is a phoenix and their colors are burgundy and silver.\n",
      "It is located on 1st and 2nd floors of Gunsolley Hall and Kyle Macali ’14 of\n",
      "Maryville, Missouri is the House President. Fitzgerald Fitness Center Located on\n",
      "the northwest end of campus just south of Tess Morgan, the Fitz, named for\n",
      "donors Bob and Janet (Braun) ’61 Fitzgerald, has been a part of the Graceland\n",
      "landscape since September 16, 2012. With the opening of the Fitz, Graceland\n",
      "celebrated a new era of student health and wellness on “the Hill.”The Fitz is a\n",
      "state-of-the-art facility with more than $150,000 in exercise equipment,\n",
      "including aerobic machines outfitted with personal viewing screens, a full\n",
      "circuit of strength-and- fitness equipment, and small, functional training\n",
      "pieces. Robert Fitzgerald said his family’s lives improved dramatically when\n",
      "they became more active a few years ago. “We hope our contribution helps\n",
      "Graceland students achieve long-term fitness lifestyles,” he said. Thanks to the\n",
      "Fitzgeralds, maintaining a healthy lifestyle has become even more affordable and\n",
      "convenient for Graceland students and employees.\n",
      "\n",
      "\n",
      "Score: 0.4931\n",
      "Page number: 2017FallHorizons.pdf\n",
      "Text:\n",
      "Draves has participated in both roles, most recently as a mentor. This highly\n",
      "competitive leadership training helps university STEM leaders overcome the\n",
      "hurdles of change and “helps to make the changes palatable,” explained Draves.\n",
      "For instance, how do leaders and faculty change the curriculum in their\n",
      "department to make it more modern and ensure that students get a quality\n",
      "education in STEM disciplines. Changes in curriculum are difficult for\n",
      "universities to accomplish. So, how do you get faculty on board and offer the\n",
      "resources? “The STEM fields move so fast that we need to be nimble — more able\n",
      "to change,” Draves explained. How did you get started in your field. I got\n",
      "interested in chemistry from a little chemistry set that I got when I was a kid.\n",
      "That’s where it really started: Mr. Wizard’s experiments in chemistry. (The\n",
      "vintage 1973 set can be purchased online.)\n",
      "\n",
      "\n",
      "Score: 0.4882\n",
      "Page number: 2009FallHorizons.pdf\n",
      "Text:\n",
      "Left: Kirk Bjorland and marketing assistant Chauntel Ranney ’88. R esidents of\n",
      "southern Iowa and northern Missouri will be seeing a new face of Graceland\n",
      "University at regional public schools sporting/special events, and at community\n",
      "gatherings. A new Graceland Yellow- jacket events trailer was rolled out for\n",
      "area 4th of July pa- rades recently and GU Marketing Director Kirk Bjorland\n",
      "expects the “Blue and Gold” of Graceland to be appearing at events around the\n",
      "region in coming months. “Graceland is truly an international university,” said\n",
      "Kirk, a 1989 GU graduate. “This past year our students hailed from 40 countries\n",
      "and represented 47 states. People sometimes forget, though, that Graceland is\n",
      "very much a regional university. We draw students from all the regional high\n",
      "schools and we are very proud of that.”He said the GU events trailer will be a\n",
      "way for Graceland to show appreciation for all the regional schools and com-\n",
      "munities, and to our current students and alumni who grew up in those\n",
      "communities. A major use for the trailer will be as a portable welcome center\n",
      "for Graceland campus visitors. The trailer will be a visible focal point where\n",
      "bus drivers, parents, coaches, and teachers bringing young people to Graceland\n",
      "events can get directions around campus, and materials about attending our\n",
      "university.\n",
      "\n",
      "\n",
      "Score: 0.4779\n",
      "Page number: 2015WinterHorizons.pdf\n",
      "Text:\n",
      "A primary focus of this issue of Horizons is celebrating Graceland’s talented\n",
      "alumni. Over the decades, Graceland has created a learning culture where our\n",
      "graduates have grown into holistic thinkers, decision makers and successful\n",
      "world citizens. But what does this really mean. To be successful in whomever we\n",
      "choose to be requires a number of things. The guiding values we choose to live\n",
      "by inform how we will think, learn and make decisions in life. It is a learning\n",
      "process on how to be true to ourselves and the world in which we live. In this\n",
      "way, meaning comes from making choices in life that can provide us joy and\n",
      "happiness, and positively impact those around us. These are not easy things to\n",
      "be and do, but living in a community that provides support and learning\n",
      "resources to actively engage in these life challenges is important. Graceland\n",
      "provides this kind of exploring, learning environment. Graceland was a starting\n",
      "point for me to learn how to think and evaluate life critically, and try to make\n",
      "good decisions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Alumna Chris Helene Bridge\"\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
    "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
    "top_results_dot_product\n",
    "\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Results:\")\n",
    "for score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    print(f\"Page number: {pages_and_chunks[idx][\"document_name\"]}\")\n",
    "    print(\"Text:\")\n",
    "    print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionizing resources\n",
    "def retrieve_relevant_resources(query: str,\n",
    "                                embeddings: torch.tensor,\n",
    "                                model: SentenceTransformer=embedding_model,\n",
    "                                n_resources_to_return: int=5,\n",
    "                                print_time: bool=True):\n",
    "    \n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    start_time = timer()\n",
    "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "    end_time = timer()\n",
    "\n",
    "    if print_time:\n",
    "        print(f\"Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "    \n",
    "    scores, indices = torch.topk(input=dot_scores,\n",
    "                                k=n_resources_to_return)\n",
    "    \n",
    "    return scores, indices\n",
    "\n",
    "def print_top_results_and_scores(query: str,\n",
    "                                 embeddings: torch.tensor,\n",
    "                                 pages_and_chunks: list[dict]= pages_and_chunks,\n",
    "                                 n_resources_to_return: int=5):\n",
    "    \n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings,\n",
    "                                                  n_resources_to_return=n_resources_to_return)\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"Results:\")\n",
    "    for scores, indices in zip(scores, indices):\n",
    "        print(f\"Score: {scores:.4f}\")\n",
    "        print(f\"Page number: {pages_and_chunks[indices][\"document_name\"]}\")\n",
    "        print(\"Text:\")\n",
    "        print_wrapped(pages_and_chunks[indices][\"sentence_chunk\"])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to get scores on 2469 embeddings: 0.00006 seconds.\n",
      "Query: Resch\n",
      "\n",
      "Results:\n",
      "Score: 0.5490\n",
      "Page number: 2010WinterHorizons.pdf\n",
      "Text:\n",
      ". . . . . . . . . . . . . . . . . . . .4,062 . .\n",
      "\n",
      "\n",
      "Score: 0.4510\n",
      "Page number: HorizonsSU18_FINAL.pdf\n",
      "Text:\n",
      "So, who among the class of 2018 will capture headlines in their lifetime. It’s\n",
      "too soon to tell. They will take many different roads as they pursue their\n",
      "passions. Some may lead to fame and fortune; others may provide more private\n",
      "satisfactions of family and friendship. It is both a thrilling and unsettling\n",
      "fact of teaching that you never know if what you’re saying may have a profound\n",
      "life-changing impact, even when you wondered if they were listening at all. A\n",
      "philosopher tells us that the goal in life is not to try to do extraordinary\n",
      "things, but to do ordinary things with an appreciation of their extraordinary\n",
      "significance. And so, we send our graduates out to do ordinary things with\n",
      "confidence that, with their Graceland experience, they will in their own\n",
      "creative ways make the world a better place. We hope they will keep in touch and\n",
      "let us know how their Graceland DNA continues to shine through in ordinary,\n",
      "extraordinarily significant ways. F R O M T H E PRESIDENT Commencement  photo\n",
      "albums  can be viewed  on Graceland's  Facebook page Horizons VOL.34, NO.\n",
      "\n",
      "\n",
      "Score: 0.4256\n",
      "Page number: 2009SpringHorizons.pdf\n",
      "Text:\n",
      "Note “Vietnam Book Project” on your check. Bringing this notable Vietnam book\n",
      "collection to Graceland and creating an informal Veterans Center are noble\n",
      "goals. Jim and Graceland thank you for being involved. Jim Barker crossing the\n",
      "finish line in the first-ever Hanoi marathon in 1993. Posing with his Vietnamese\n",
      "Intel team at Kon Tum during the Vietnam War. Ray Chase throws out the first\n",
      "ball. The 2008-09 GU Baseball Team. Ray shakes hands with Lamoni Mayor Jim\n",
      "Hammer. Ray is honored and receives mementos of the day. Alu mni E xcellence Alu\n",
      "mni E xcellence Jim Barker — a hero in Vietnam, a hero at home You Can Help\n",
      "Bring Vietnam Books to GU GRACELAND HORIZONS SPRING/SUMMER 2009 GRACELAND\n",
      "HORIZONS SPRING/SUMMER 2009 GRACELAND HORIZONS SPRING/SUMMER 2009\n",
      "\n",
      "\n",
      "Score: 0.4136\n",
      "Page number: 2009FallHorizons.pdf\n",
      "Text:\n",
      "Many people come to us to say ‘thank you.’”The Sinkhani continue to volunteer on\n",
      "a weekly basis to weigh babies and teach mothers. Last year they weighed over\n",
      "26,000 babies. Their big request is for money to buy uniforms. According to\n",
      "them, everyone that works in the health care system has uniforms except them.\n",
      "They calculated the cost and said it would be $121 for fabric and a tailor for\n",
      "the 13 uniforms they would like to have. After 17 years of volunteer work, a\n",
      "$9.30 uniform seems like a reasonable request. We’ll work it into next year’s\n",
      "budget. A long but very successful trip. New contacts and support possibilities\n",
      "emerge everyday as news of the new OVC programs spread.\n",
      "\n",
      "\n",
      "Score: 0.3888\n",
      "Page number: 2009FallHorizons.pdf\n",
      "Text:\n",
      "“They changed me from the 800 to the mile at Graceland, and now I am a miler at\n",
      "heart.”She was a five-time All-American for Graceland during her junior and\n",
      "senior years. She received fifth place in the mile and third in the 1,500 at the\n",
      "NAIA national meet as a junior. She placed fourth in cross country and earned a\n",
      "national title in the mile to cap off her senior year of indoor track. She\n",
      "followed with a fourth place during the spring outdoor season in the 1,500. “Up\n",
      "until this year, I was the only All-American in cross country for Graceland,”\n",
      "she said. “I was also re- cently inducted into Graceland’s Hall of\n",
      "Fame.”Eligibility begins five years past graduation. Kristy is currently the\n",
      "youngest member. Wanting to compete after college, Kristy was one of the\n",
      "founding runners of the Elite Development Club, based mostly in Des Moines.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Resch\"\n",
    "print_top_results_and_scores(query=query,embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking hardware relative to LLM model\n",
    "#7b model size model is what we'll be looking for this project.\n",
    "\n",
    "import torch\n",
    "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "gpu_memory_gb = round(gpu_memory_bytes / (2**30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory: 12 | Recommended model: Gemma2 2B in float16 or Gemma 7B in 4-bit precision.\n",
      "use_quantization_config set to: False\n",
      "model_id set to: google/gemma2-2b-it\n"
     ]
    }
   ],
   "source": [
    "if gpu_memory_gb < 5.1:\n",
    "    print(f\"Your available GPU memory is {gpu_memory_gb}GB, you may not have enough memory to run a Gemma LLM locally without quantization.\")\n",
    "elif gpu_memory_gb < 8.1:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma2 2B in 4-bit precision.\")\n",
    "    use_quantization_config = True \n",
    "    model_id = \"google/gemma2-2b-it\"\n",
    "elif gpu_memory_gb < 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma2 2B in float16 or Gemma 7B in 4-bit precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"google/gemma2-2b-it\"\n",
    "elif gpu_memory_gb > 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommend model: Gemma2 7B in 4-bit or float16 precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"google/gemma2-7b-it\"\n",
    "\n",
    "print(f\"use_quantization_config set to: {use_quantization_config}\")\n",
    "print(f\"model_id set to: {model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.utils import is_flash_attn_2_available\n",
    "\n",
    "# Create quantization config\n",
    "from transformers import BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "dot_env_path = find_dotenv()\n",
    "load_dotenv(dot_env_path)\n",
    "access_token = os.getenv(\"HUGGING_FACE_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b114b4b78b564e3490bee6d23f924366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading LLM\n",
    "# Model: gemma 7b\n",
    "# Use Flash Attention 2 if possible\n",
    "\n",
    "#login to huggingface\n",
    "login(token=access_token)\n",
    "print(\"Logged in successfully!\")\n",
    "\n",
    "# Flash attention 2 if possible\n",
    "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0] >= 8):\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "    attn_implementation = \"sdpa\"\n",
    "\n",
    "# Loading model\n",
    "model_id = \"google/gemma-2-2b-it\"\n",
    "\n",
    "# Instantiate tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "\n",
    "# Load model\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    token=access_token,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None,\n",
    "    attn_implementation=attn_implementation\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma2ForCausalLM(\n",
       "  (model): Gemma2Model(\n",
       "    (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-25): 26 x Gemma2DecoderLayer(\n",
       "        (self_attn): Gemma2Attention(\n",
       "          (q_proj): Linear(in_features=2304, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
       "        )\n",
       "        (mlp): Gemma2MLP(\n",
       "          (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "          (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "          (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "    (rotary_emb): Gemma2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2304, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect model\n",
    "llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "Tell me about the Resch building.\n"
     ]
    }
   ],
   "source": [
    "inputs_text = \"Tell me about the Resch building.\"\n",
    "print(f\"Input text:\\n{inputs_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt (formatted):\n",
      "<bos><start_of_turn>user\n",
      "Tell me about the Resch building.<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialog_template = [\n",
    "    {\"role\":\"user\",\n",
    "     \"content\": inputs_text}\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(conversation=dialog_template,\n",
    "                                       tokenize=False,\n",
    "                                       add_generation_prompt=True)\n",
    "\n",
    "print(f\"\\nPrompt (formatted):\\n{prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaTokenizerFast(name_or_path='google/gemma-2-2b-it', vocab_size=256000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<bos>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<start_of_turn>', '<end_of_turn>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<eos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<bos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t5: AddedToken(\"<2mass>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t6: AddedToken(\"[@BOS@]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t7: AddedToken(\"<unused0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t8: AddedToken(\"<unused1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t9: AddedToken(\"<unused2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t10: AddedToken(\"<unused3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t11: AddedToken(\"<unused4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t12: AddedToken(\"<unused5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t13: AddedToken(\"<unused6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t14: AddedToken(\"<unused7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t15: AddedToken(\"<unused8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t16: AddedToken(\"<unused9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t17: AddedToken(\"<unused10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t18: AddedToken(\"<unused11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t19: AddedToken(\"<unused12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20: AddedToken(\"<unused13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t21: AddedToken(\"<unused14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t22: AddedToken(\"<unused15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t23: AddedToken(\"<unused16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t24: AddedToken(\"<unused17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t25: AddedToken(\"<unused18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t26: AddedToken(\"<unused19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t27: AddedToken(\"<unused20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t28: AddedToken(\"<unused21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t29: AddedToken(\"<unused22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t30: AddedToken(\"<unused23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t31: AddedToken(\"<unused24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t32: AddedToken(\"<unused25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t33: AddedToken(\"<unused26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t34: AddedToken(\"<unused27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t35: AddedToken(\"<unused28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t36: AddedToken(\"<unused29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t37: AddedToken(\"<unused30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t38: AddedToken(\"<unused31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t39: AddedToken(\"<unused32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t40: AddedToken(\"<unused33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t41: AddedToken(\"<unused34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t42: AddedToken(\"<unused35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t43: AddedToken(\"<unused36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t44: AddedToken(\"<unused37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t45: AddedToken(\"<unused38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t46: AddedToken(\"<unused39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t47: AddedToken(\"<unused40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t48: AddedToken(\"<unused41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t49: AddedToken(\"<unused42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t50: AddedToken(\"<unused43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t51: AddedToken(\"<unused44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t52: AddedToken(\"<unused45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t53: AddedToken(\"<unused46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t54: AddedToken(\"<unused47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t55: AddedToken(\"<unused48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t56: AddedToken(\"<unused49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t57: AddedToken(\"<unused50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t58: AddedToken(\"<unused51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t59: AddedToken(\"<unused52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t60: AddedToken(\"<unused53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t61: AddedToken(\"<unused54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t62: AddedToken(\"<unused55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t63: AddedToken(\"<unused56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t64: AddedToken(\"<unused57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t65: AddedToken(\"<unused58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t66: AddedToken(\"<unused59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t67: AddedToken(\"<unused60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t68: AddedToken(\"<unused61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t69: AddedToken(\"<unused62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t70: AddedToken(\"<unused63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t71: AddedToken(\"<unused64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t72: AddedToken(\"<unused65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t73: AddedToken(\"<unused66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t74: AddedToken(\"<unused67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t75: AddedToken(\"<unused68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t76: AddedToken(\"<unused69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t77: AddedToken(\"<unused70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t78: AddedToken(\"<unused71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t79: AddedToken(\"<unused72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t80: AddedToken(\"<unused73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t81: AddedToken(\"<unused74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t82: AddedToken(\"<unused75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t83: AddedToken(\"<unused76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t84: AddedToken(\"<unused77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t85: AddedToken(\"<unused78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t86: AddedToken(\"<unused79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t87: AddedToken(\"<unused80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t88: AddedToken(\"<unused81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t89: AddedToken(\"<unused82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t90: AddedToken(\"<unused83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t91: AddedToken(\"<unused84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t92: AddedToken(\"<unused85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t93: AddedToken(\"<unused86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t94: AddedToken(\"<unused87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t95: AddedToken(\"<unused88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t96: AddedToken(\"<unused89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t97: AddedToken(\"<unused90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t98: AddedToken(\"<unused91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t99: AddedToken(\"<unused92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t100: AddedToken(\"<unused93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t101: AddedToken(\"<unused94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t102: AddedToken(\"<unused95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t103: AddedToken(\"<unused96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t104: AddedToken(\"<unused97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t105: AddedToken(\"<unused98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t106: AddedToken(\"<start_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t107: AddedToken(\"<end_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t108: AddedToken(\"\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t109: AddedToken(\"\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t110: AddedToken(\"\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t111: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t112: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t113: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t114: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t115: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t116: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t117: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t118: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t119: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t120: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t121: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t122: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t123: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t124: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t125: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t126: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t127: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t128: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t129: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t130: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t131: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t132: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t133: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t134: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t135: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t136: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t137: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t138: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t139: AddedToken(\"▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t140: AddedToken(\"▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t141: AddedToken(\"▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t142: AddedToken(\"▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t143: AddedToken(\"▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t144: AddedToken(\"▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t145: AddedToken(\"▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t146: AddedToken(\"▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t147: AddedToken(\"▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t148: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t149: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t150: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t152: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t153: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t154: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t155: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t156: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t157: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t158: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t159: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t160: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t161: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t162: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t163: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t164: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t165: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t166: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t167: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t168: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t169: AddedToken(\"<table>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t170: AddedToken(\"<caption>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t171: AddedToken(\"<thead>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t172: AddedToken(\"<tbody>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t173: AddedToken(\"<tfoot>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t174: AddedToken(\"<tr>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t175: AddedToken(\"<th>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t176: AddedToken(\"<td>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t177: AddedToken(\"</table>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t178: AddedToken(\"</caption>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t179: AddedToken(\"</thead>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t180: AddedToken(\"</tbody>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t181: AddedToken(\"</tfoot>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t182: AddedToken(\"</tr>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t183: AddedToken(\"</th>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t184: AddedToken(\"</td>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t185: AddedToken(\"<h1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t186: AddedToken(\"<h2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t187: AddedToken(\"<h3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t188: AddedToken(\"<h4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t189: AddedToken(\"<h5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t190: AddedToken(\"<h6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t191: AddedToken(\"<blockquote>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t192: AddedToken(\"</h1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t193: AddedToken(\"</h2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t194: AddedToken(\"</h3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t195: AddedToken(\"</h4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t196: AddedToken(\"</h5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t197: AddedToken(\"</h6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t198: AddedToken(\"</blockquote>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t199: AddedToken(\"<strong>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t200: AddedToken(\"<em>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t201: AddedToken(\"<b>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t202: AddedToken(\"<i>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t203: AddedToken(\"<u>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t204: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t205: AddedToken(\"<sub>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t206: AddedToken(\"<sup>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t207: AddedToken(\"<code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t208: AddedToken(\"</strong>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t209: AddedToken(\"</em>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t210: AddedToken(\"</b>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t211: AddedToken(\"</i>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t212: AddedToken(\"</u>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t213: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t214: AddedToken(\"</sub>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t215: AddedToken(\"</sup>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t216: AddedToken(\"</code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255968: AddedToken(\"[toxicity=0]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255969: AddedToken(\"\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255970: AddedToken(\"\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255971: AddedToken(\"\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255972: AddedToken(\"\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255973: AddedToken(\"\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255974: AddedToken(\"\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255975: AddedToken(\"\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255976: AddedToken(\"\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255977: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255978: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255979: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255980: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255981: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255982: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255983: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255984: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255985: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255986: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255987: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255988: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255989: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255990: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255991: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255992: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255993: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255994: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255995: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255996: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255997: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255998: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255999: AddedToken(\"<unused99>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "Tell me about North Park.\n",
      "model\n",
      "## North Park: A Vibrant Neighborhood in San Diego\n",
      "\n",
      "North Park is a diverse and trendy neighborhood in San Diego, California, known for its unique blend of eclectic shops, restaurants, breweries, and nightlife.  Here's a glimpse:\n",
      "\n",
      "**What makes North Park special?**\n",
      "\n",
      "* **Eclectic Vibe:** It boasts a bohemian, artsy feel with vintage shops, independent boutiques, and quirky cafes. \n",
      "* **Foodie Paradise:** From farm-to-table restaurants to trendy food trucks, North Park offers a culinary scene that caters to every palate.\n",
      "* **Craft Beer Capital:** Home to numerous craft breweries and brewpubs, North Park is a haven for beer lovers. \n",
      "* **Outdoor Activities:** The neighborhood boasts a vibrant park scene with the popular **North Park Community Park**, a dog-friendly space with a playground and grassy fields.\n",
      "* **Walkable and bikeable:** North Park is a pedestrian-friendly neighborhood, with a network of well-maintained sidewalks and bike lanes.\n",
      "* **Community Spirit:** North Park has a strong sense of community, hosting numerous farmers' markets, festivals, and local events throughout the year.\n",
      "\n",
      "**What to expect in North Park:**\n",
      "\n",
      "* **Shopping:** Unique boutiques, vintage shops, art galleries, record stores, and independent bookstores.\n",
      "* **Dining:** Diverse culinary scene with trendy restaurants, casual cafes, food trucks, and international cuisines.\n",
      "* **Breweries and Bars:** A wide selection of craft breweries, taprooms, and cocktail bars with live music and outdoor seating.\n",
      "* **Art and Culture:** Art galleries, music venues, theaters, and street art.\n",
      "* **Parks and Recreation:** North Park Community Park, scenic trails, and open spaces for recreation.\n",
      "\n",
      "**Things to do in North Park:**\n",
      "\n",
      "* **Explore the shops and boutiques:** From clothing and home goods to quirky finds and handmade crafts, North Park offers a diverse shopping experience.\n",
      "* **Savor the diverse culinary scene:** Indulge in everything from farm-to-table fare to international cuisine.\n",
      "* **Discover the craft beer scene:** Sample local brews at renowned breweries and taprooms.\n",
      "* **Enjoy outdoor activities:** Spend time at North Park Community Park, hike or bike the scenic trails, or relax at a patio bar.\n",
      "* **Attend local events:** Check out the schedule for farmers' markets, festivals, concerts, and art exhibitions.\n",
      "\n",
      "**Getting around:**\n",
      "\n",
      "* **Public Transportation:**  The neighborhood is well-connected to public\n",
      "CPU times: total: 25.2 s\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt = \"Tell me about North Park.\"\n",
    "\n",
    "dialog_template = [\n",
    "    {\"role\":\"user\",\n",
    "     \"content\": prompt}\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(conversation=dialog_template,\n",
    "                                       tokenize=False,\n",
    "                                       add_generation_prompt=True)\n",
    "\n",
    "# Tokenize and move to GPU\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"].to(\"cuda\")\n",
    "attention_mask = inputs[\"attention_mask\"].to(\"cuda\")\n",
    "\n",
    "# Generate\n",
    "outputs = llm_model.generate(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95\n",
    ")\n",
    "\n",
    "# Decode the output\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter(query: str,\n",
    "                     context_items: list[dict]) -> str:\n",
    "    context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_items])\n",
    "\n",
    "    base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
    "    Context items:\n",
    "{context}\n",
    "    Query: {query}\n",
    "    Answer: \n",
    "    \"\"\"\n",
    "\n",
    "    prompt = base_prompt.format(context=context,\n",
    "                                query=query)\n",
    "    return prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to get scores on 2469 embeddings: 0.00008 seconds.\n",
      "Based on the following context items, please answer the query.\n",
      "    Context items:\n",
      "- Anne sees each addition to the milking herd she now owns as a distinct character and names her accordingly after an appropriate performer, goddess, NPR news broadcaster, or politician. There will likely be a Hillary frolicking among this season’s kids. Anne’s father (John Rufus Topham ’28) coached her on the finer points of hand milking, and her quest for the best use of the pure, white goat milk was on. Anne wanted to re-create the first goat cheese she had ever tasted, a confection that had been carried from Paris to Madison by the mother of a college friend. “It was a lovely, blooming-rind round of cheese resting on a bed of straw, and I’ve never forgotten it,” she says. Anne’s mother, Alta Royer ’28 Topham, was a piano stu- dent at GU and went on to become a valued member of the first RLDS Hymnal Committee. “My mother drove a Model T all around the Iowa countryside, playing the piano and giving lessons,” says Anne. “She was an amazing woman.” Anne credits Graceland with “…giving me a great start in life. My work with the wonderful Professor (Emerita) Velma Ruch (’41), the high level of academics, it all prepared me well for the challenges of the University of Wisconsin.”\n",
      "- 11 The Industrial Department offered work-study opportunities at GRACELAND-OWNED FARMS beginning in 1906, with chickens, pigs, a team of horses and a cow.12 Today, GRACELAND SUSTAINABILITY manages an eco plot of an acre of land at the northeastern corner of the Lamoni campus. It is made up of the Persall Orchard and Gazebo, fruit and nut tree plantings, a 20' x 80' hoop house/high tunnel with raised beds and an outdoor garden with raised beds.13 BIG G LAKE was constructed in 1959, and in 1960, the concrete “G,” measuring 72 feet from top to bottom, was laid to be seen from the west football stands.14 The concrete BIG G was redone in 2011, and for Homecoming 2012, honor class gifts provided funding that turned the space into a park for student use. It now includes a parking area, picnic tables and barbecue grills for everyone to enjoy.15 The CHAPEL IN THE GROVE was an outdoor bandstand completed in 1959 and was located south of the F. M. Smith Library. It was used for graduations and some major theatrical productions.16 The SHAW CENTER AMPHITHEATRE was created as part of the Shaw Center renovations in 2012 and hosts crowds for homecomings, Spectacular and other gatherings, including classes that take their lessons outdoors on nice days. Send your requests or photos to:  communications@graceland.edu or to  1 University Place, Lamoni, IA 50140,  attention Horizons Do you have any old photos or a favorite spot on campus to compare to current campus settings?\n",
      "- That acceptance gives us the courage and determination to reflect on our weaknesses as well as our strengths and to continue to strive for that elusive wholeness we have sensed in our days at Graceland. Let’s celebrate. Let’s celebrate what we have accomplished together and how we can build on that. Together we celebrate the milestones along the way and the journey ahead. In addition to his magnetic charm and the warmth he brought to the Graceland community, Brad was attracted to music at a young age and played guitar in many bands throughout his life; one could often hear the sound of faint guitar coming from his office in the Memorial Student Center between events or on a slow afternoon. He loved to ride motorcycles, play golf and spend time outdoors. He took an interest in disc golf at Graceland and pioneered the construction of a course on campus, later facilitating disc golf tournaments in Lamoni and on campus. Brad left this life suddenly Jan. 28, leaving a hole in the hearts of many. Memorial services were appropriately held in the MSC Main Room on the Graceland Lamoni, Iowa, campus Saturday, Feb. 3. A visitation the evening before brought friends from all over to celebrate a life and love held dear for decades.\n",
      "- 22 |  Horizons SUMMER 2017 1 5 9 13 3 7 11 15 2 6 10 14 4 8 12 16 1 The HIGDON ADMINISTRATION BUILDING was constructed in 1897 and was the first building on what is now the Lamoni campus. This image was taken of the building in 1943. A \"fleet\" of sheep was purchased to assist in “mowing” the campus lawn during World War II.2 Renovation of the HIGDON ADMINISTRATION BUILDING was completed in 1997. It now stands in the center of campus and has become known as the symbol of Graceland University.3 BRIGGS HALL opened in 1921 and is the second oldest building at Graceland. It has been used as everything from a dormitory, classrooms, the campus library, hospital and dining hall to offices.4 The BRIGGS stairs are known to generations of Gracelanders as the most intimidating on campus. The building has not experienced any major renovations and is in need of updates. It is included as a part of the current $24 million Life on the Hill campaign.\n",
      "- GRACELAND HORIZONS SPRING/SUMMER 2011 24 T here is a new guy in the Resch Science and Tech- nology Hall who is so skinny he is not even skin and bones. He is just bones. His name is ‘Larry,’ Larry the skeleton. Graceland Professor Teri Foster and her anatomy and physiology students just love him. He is named for Larry Phillips, owner, along with his wife Linda, of the venerable Varsity Drug store in down- town Lamoni. Larry and Linda have owned and operated Varsity Drug for 13 years, when they made the move here from Centerville, IA. They love Lamoni, and they love Graceland University, and they give a lot of themselves to both. They are among those who actively volunteer in the work of developing a brighter future for our community, and especially our youth. That includes the young people at Graceland. It was in that spirit of giving back that the Phillips recently gifted ‘Larry,’ Larry the skeleton, to the science program at Graceland.\n",
      "    Query: Tell me about the Resch building.\n",
      "    Answer: \n",
      "    \n",
      "Query: Tell me about the Resch building.\n",
      "RAG answer:\n",
      "<bos>The Resch Science and Technology Hall is a new building at Graceland University. It is home to Professor Teri Foster and her students. \n",
      "    \n",
      "    \n",
      "<end_of_turn>\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me about the Resch building.\"\n",
    "\n",
    "scores, indices = retrieve_relevant_resources(query=prompt,\n",
    "                                              embeddings=embeddings)\n",
    "\n",
    "context_items = [pages_and_chunks[i] for i in indices]\n",
    "\n",
    "prompt = prompt_formatter(query=query,\n",
    "                          context_items=context_items)\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             temperature=0.5,\n",
    "                             do_sample=True,\n",
    "                             max_new_tokens=512)\n",
    "\n",
    "output_text = tokenizer.decode(outputs[0])\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"RAG answer:\\n{output_text.replace(prompt, '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes query and finds relevant news articles and then generates an answer based on the relevant resources.\n",
    "def ask(query: str,\n",
    "        temperature: float=0.7,\n",
    "        max_new_tokens: int=512,\n",
    "        fromat_answer_text = True,\n",
    "        return_answer_only = True):\n",
    "    \n",
    "    # Retrieval \n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                 embeddings=embeddings)\n",
    "    \n",
    "    context_items = [pages_and_chunks[i] for i in indices]\n",
    "\n",
    "    for i, item in enumerate(context_items):\n",
    "        item[\"score\"] = scores[i].cpu()\n",
    "\n",
    "\n",
    "    # Augmentation\n",
    "    prompt = prompt_formatter(query=query,\n",
    "                              context_items=context_items)\n",
    "    \n",
    "    \n",
    "    #Generation\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    outputs = llm_model.generate(**input_ids,\n",
    "                                 temperature= temperature,\n",
    "                                 do_sample = True,\n",
    "                                 max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "    if fromat_answer_text:\n",
    "        output_text = output_text.replace(prompt, \"\").replace(\"<bos>\", \"\").replace(\"<eos>\",\"\")\n",
    "    \n",
    "    if return_answer_only:\n",
    "        return output_text, context_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to get scores on 2469 embeddings: 0.00006 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('\"The context you provided does not mention North Park.\" \\n<end_of_turn>',\n",
       " [{'document_name': '2009SpringHorizons.pdf',\n",
       "   'sentence_chunk': 'Join me in celebrating a handful of the thousands of ‘Graceland Stories’ we would like to tell. The stellar alumni you will read about here graduated as long ago as 1953 and as recently as 2008. Their visions and efforts cover the gamut of the human experience. I champion their achievements. To all Gracelanders I would like to say, hold on to your most-cherished goals and be guided by the life-path vi- sions you took away from this university. Do you remem- ber the dreams you had on your Commencement Day? Reach for them.     John Sellars      President Administration John Sellars, Ph. D. \\t President Steven L. Anders, Ph. D. ’73 \\t Vice President for Academic Affairs and Dean of Faculty Kathleen M. Clauson Bash, Ph. D. \\t Vice President for Institutional Effectiveness Kelly W. Everett, B. A. ’77 \\t Vice President for Institutional Advancement Sharon M. Kirkpatrick, Ph. D. ’65 \\t Vice President for Independence Campus Thomas L. Powell, M. A. ’73 \\t Vice President for Student Life and Dean of Students Jodi L. Seymour \\t Executive Assistant to the President \\t and Assistant Secretary to the Board of Trustees Gregory S. Sutherland, B. A. ’73 \\t Vice President for Enrollment and Dean of Admissions Janice K. Tiffany, B. A. ’83 \\t Vice President for Business and Administrative Services Board of Trustees Kenneth B. McClain, J. D. ’79, Chair Jennings Jay Newcom, J. D. ’64 , Vice Chair Cheryl F. Hansen, ’77, Secretary Matthew J. Beem Hon. Leonard L. Boswell ’55 Orman Brooner ’53 Donald P. Brown ’57 Robert P. Bruch ’52 David B. Carmichael ’42 \\t M. D., M. A. C. C., RADM MC USNR (Ret.) Denise Dudley, Ph. D. Calvin V. French, Ed.',\n",
       "   'chunk_char_count': 1633,\n",
       "   'chunk_word_count': 294,\n",
       "   'chunk_token_count': 408.25,\n",
       "   'score': tensor(0.4218)},\n",
       "  {'document_name': '2009FallHorizons.pdf',\n",
       "   'sentence_chunk': 'Anne sees each addition to the milking herd she now owns as a distinct character and names her accordingly after an appropriate performer, goddess, NPR news broadcaster, or politician. There will likely be a Hillary frolicking among this season’s kids. Anne’s father (John Rufus Topham ’28) coached her on the finer points of hand milking, and her quest for the best use of the pure, white goat milk was on. Anne wanted to re-create the first goat cheese she had ever tasted, a confection that had been carried from Paris to Madison by the mother of a college friend. “It was a lovely, blooming-rind round of cheese resting on a bed of straw, and I’ve never forgotten it,” she says. Anne’s mother, Alta Royer ’28 Topham, was a piano stu- dent at GU and went on to become a valued member of the first RLDS Hymnal Committee. “My mother drove a Model T all around the Iowa countryside, playing the piano and giving lessons,” says Anne. “She was an amazing woman.” Anne credits Graceland with “…giving me a great start in life. My work with the wonderful Professor (Emerita) Velma Ruch (’41), the high level of academics, it all prepared me well for the challenges of the University of Wisconsin.”',\n",
       "   'chunk_char_count': 1193,\n",
       "   'chunk_word_count': 210,\n",
       "   'chunk_token_count': 298.25,\n",
       "   'score': tensor(0.4165)},\n",
       "  {'document_name': 'GracelandU-Horizons_FA23-WEB-NEW.pdf',\n",
       "   'sentence_chunk': \"29 into the National Guild of Hypnotists, the highest level of association in the organization. Fewer than .25% of hypnotists achieve this accomplishment.\\uf128\\u20063 15\\u2006 Alex Carr, Coralville, Iowa, is the new owner of Thrivent Mississippi Valley Associates financial planning practice, and also assumed command of the United States Army Reserves 389th Engineer Battalion's HHC unit as Company Commander.\\uf128\\u20064 19\\u2006 Ryan C. Tittle, Sumiton, Alabama, won second prize in Blue Institute’s 5th annual Words on Water Writing Contest with the poem “The Rain Dance.”BIRTHS 06\\u2006 Shane and Marilyn Everett, Grand Prairie, Texas, son Evan Blake, born April 21, 2021. 07\\u2006 Chad and Brittany Everett, Lexington, North Carolina, son Kline Cole, born April 8, 2019, and son Drake Reed, born Dec. 21, 2022. WEDDINGS 16\\u2006 Benjamin Landers and Natalie Sherer, Portland, Oregon, June 22, 2019. ANNIVERSARIES 51\\u2006 Lloyd and Joan Fenn ’49 Slaght, Blue Springs, Missouri, 70 years, June 14, 2023. 60\\u2006 Howard and Bonita Booth, Lamoni, Iowa, 60 years, June 29, 2023.66\\u2006 Robert and Gayle Boren ’88, Corvallis, Oregon, 55 years, June 2, 2023.\",\n",
       "   'chunk_char_count': 1102,\n",
       "   'chunk_word_count': 173,\n",
       "   'chunk_token_count': 275.5,\n",
       "   'score': tensor(0.3663)},\n",
       "  {'document_name': 'Horizons-Winter2017v2.pdf',\n",
       "   'sentence_chunk': 'WINTER 2017 Horizons  | 13 A manda Deering Jones ’01 believes she made one of the best decisions of her life when she decided to become a theatre major at Graceland University. With an already developed interest in ﬁlm, the Sarasota, Florida, native grew up in the Community of Christ and aware of Graceland. When it came time to choose a college, she knew she wanted to go somewhere with smaller classes and better access to faculty. A visit to Graceland offered a feeling of comfort and familiarity.years, has won seven so far, and was nominat- ed for an Academy Award for Best Animated Short in 2017. “The success of Borrowed Time is beyond thrilling, and the experience has changed my life,” says Amanda. But she says the deeper purpose to affect and reach peo- ple has made all her hard work worthwhile. Amanda doesn’t stop at ﬁlm when making a difference, however. In her personal life, she has spent the last several years trying to move toward a zero-waste lifestyle. “My husband and I have made great strides, and I try to share what I learn with everyone I know, because most of the changes are pretty easy to implement; it comes down to a choice and voting with your wallet.”',\n",
       "   'chunk_char_count': 1186,\n",
       "   'chunk_word_count': 213,\n",
       "   'chunk_token_count': 296.5,\n",
       "   'score': tensor(0.3441)},\n",
       "  {'document_name': '2011SpSumHorizons.pdf',\n",
       "   'sentence_chunk': 'GRACELAND HORIZONS SPRING/SUMMER 2011 24 T here is a new guy in the Resch Science and Tech- nology Hall who is so skinny he is not even skin and bones. He is just bones. His name is ‘Larry,’ Larry the skeleton. Graceland Professor Teri Foster and her anatomy and physiology students just love him. He is named for Larry Phillips, owner, along with his wife Linda, of the venerable Varsity Drug store in down- town Lamoni. Larry and Linda have owned and operated Varsity Drug for 13 years, when they made the move here from Centerville, IA. They love Lamoni, and they love Graceland University, and they give a lot of themselves to both. They are among those who actively volunteer in the work of developing a brighter future for our community, and especially our youth. That includes the young people at Graceland. It was in that spirit of giving back that the Phillips recently gifted ‘Larry,’ Larry the skeleton, to the science program at Graceland.',\n",
       "   'chunk_char_count': 951,\n",
       "   'chunk_word_count': 166,\n",
       "   'chunk_token_count': 237.75,\n",
       "   'score': tensor(0.3369)}])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"North Park\"\n",
    "\n",
    "ask(query=query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
